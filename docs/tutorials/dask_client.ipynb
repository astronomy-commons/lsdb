{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5e73fdd",
   "metadata": {},
   "source": [
    "# Setting up a Dask Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2ca74c",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this tutorial, you will have a general understanding of:\n",
    "- What the Dask client is.\n",
    "- Two methods for initializing a Dask client: a context manager and a persistent client.\n",
    "- The most common arguments for configuring a Dask client.\n",
    "\n",
    "If you would like to know more, see:\n",
    "- Our [Dask cluster configuration](https://docs.lsdb.io/en/stable/tutorials/dask-cluster-tips.html) page for LSDB-specific tips.\n",
    "- The [official Dask documentation](https://distributed.dask.org/en/latest/client.html) for more general information.\n",
    "- Dask's own [best practices](https://docs.dask.org/en/stable/best-practices.html), which may also be useful to consult."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5a0321",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Dask is a framework that allows us to take advantage of distributed computing capabilities. \n",
    "\n",
    "It is recommended to use Dask when using LSDB; otherwise, LSDB uses a single CPU core, which is extremely slow for large datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84137686",
   "metadata": {},
   "source": [
    "## 1 - Launching a Dask client using a context manager\n",
    "\n",
    "This is most commonly seen when running HATS import pipelines.\n",
    "\n",
    "Using a context manager is convenient because it ensures the client is automatically closed when the context block is exited, preventing resource leaks.\n",
    "\n",
    "This is useful for temporary tasks where the client is only needed for a specific operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9755dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from hats_import.catalog.arguments import ImportArguments\n",
    "from hats_import.pipeline import pipeline_with_client\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Define arguments for the import pipeline\n",
    "    args = ImportArguments(\n",
    "        ra_column=\"ra\",\n",
    "        dec_column=\"dec\",\n",
    "        # ...\n",
    "    )\n",
    "    # Use a context manager to create and close the Dask client automatically\n",
    "    with Client(\n",
    "        n_workers=10,  # Number of workers\n",
    "        threads_per_worker=1,  # Threads per worker\n",
    "        # ...\n",
    "    ) as client:\n",
    "        pipeline_with_client(args, client)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a562a",
   "metadata": {},
   "source": [
    "## 2 - Launching a persistent Dask client\n",
    "\n",
    "Sometimes it's easier to have the Dask client live throughout the entire notebook.\n",
    "\n",
    "This is especially useful for workflows that span multiple cells and require the client to remain active throughout the notebook.\n",
    "\n",
    "Note that if you use this approach, you'll need to manually close the client when you're done using it (typically, at the end of the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78740204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(n_workers=4, threads_per_worker=1, memory_limit=\"auto\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9b9339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ece29e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f4345a",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3 - Common arguments\n",
    "\n",
    "There are a few arguments the LSDB team finds most useful. They are briefly explained as follows; for more explanation, see our [Dask cluster configuration](https://docs.lsdb.io/en/stable/tutorials/dask-cluster-tips.html) page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a2f5bf",
   "metadata": {},
   "source": [
    "### 3.1 - `n_workers`\n",
    "\n",
    "- The number of Dask workers (or Python processes) to run.\n",
    "- Increasing `n_workers` allows for more parallelism, but may also increase resource usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383a715e",
   "metadata": {},
   "source": [
    "### 3.2 - `threads_per_worker`\n",
    "\n",
    "- Specifies how many Python threads each worker can use.\n",
    "- It's generally better to keep this low (1 or 2) to avoid contention between threads.\n",
    "- Instead, scale up the `n_workers` argument to increase parallelism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9a3b0d",
   "metadata": {},
   "source": [
    "### 3.3 - `memory_limit`\n",
    "\n",
    "- Specifies how much memory each worker is allocated.\n",
    "- Generally, we find diminishing returns beyond **10 GB per thread**.\n",
    "- For example, if `memory_limit=\"20GB\"` and `threads_per_worker=2`, each thread will be allocated 10 GB.\n",
    "- You can also set `memory_limit=\"auto\"` to let Dask automatically allocate based on the available system memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfe2def",
   "metadata": {},
   "source": [
    "### 3.4 - `local_directory`\n",
    "\n",
    "- Specifies where Dask workers store temporary files.\n",
    "- Useful if the default system temp directory has limited space (e.g., pointing to a /data/ directory with more available disk space).\n",
    "- Using a temporary directory can also help manage cleanup automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4001a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "tmp_path = tempfile.TemporaryDirectory()\n",
    "tmp_dir = tmp_path.name\n",
    "\n",
    "client = Client(local_directory=tmp_dir)\n",
    "\n",
    "# Do things here.\n",
    "\n",
    "client.close()\n",
    "tmp_path.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf898d",
   "metadata": {},
   "source": [
    "## About\n",
    "**Author(s):** Olivia Lynn and Melissa DeLucchi\n",
    "\n",
    "**Last updated on:** May 22, 2025\n",
    "\n",
    "If you use lsdb for published research, please cite following [instructions](https://docs.lsdb.io/en/stable/citation.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
