{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1cb6a4-a0bc-44f2-ae48-d4de23e14c56",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Row Filtering\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "In this tutorial, we will demonstrate how to:\n",
    "\n",
    "- Set up a Dask client and open an object catalog\n",
    "- Filter rows of data by expressions involving column values\n",
    "- Do quick previews of catalog data and query results\n",
    "\n",
    "## Introduction\n",
    "\n",
    "When a catalog is opened, it is available for operations.  However, its data is is lazily loaded, and operations on it are unrealized, until computation is called for explicitly (using the `.compute()` method) or implicitly, with data preview functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb2d314-32c8-4705-b980-f424ede22af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsdb\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2606cc9-648a-49ac-bbe6-17dfe1f9309f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Open a catalog\n",
    "\n",
    "We create a basic dask client, and open an existing HATS catalogâ€”the ZTF DR14 catalog."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2225843f",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    ".. nbinfo::\n",
    "    Additional Help \n",
    "    \n",
    "    For additional information on dask client creation, please refer to the \n",
    "    `official Dask documentation <https://distributed.dask.org/en/latest/client.html>`__ \n",
    "    and our :doc:`Dask cluster configuration </tutorials/dask-cluster-tips>` page for LSDB-specific tips. \n",
    "    Note that dask also provides its own `best practices <https://docs.dask.org/en/stable/best-practices.html>`__, which may also be useful to consult.\n",
    "    \n",
    "    For tips on accessing remote data, see our :doc:`Accessing remote data tutorial </tutorials/remote_data>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e016346d-bf3e-43eb-a988-ec975823b09f",
   "metadata": {},
   "source": [
    "Create a basic Dask client, limiting the number of workers. This keeps subsequent operations from using more of our compute resources than we might intend, which is helpful in any case but especially when working on a shared resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16078b4-47b8-4939-83c4-1ad28bf1592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=4, memory_limit=\"auto\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8520df60-167d-42f8-bc2c-e771d4ff75bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ztf_object_path = \"https://data.lsdb.io/hats/ztf_dr14/ztf_object\"\n",
    "ztf_object = lsdb.open_catalog(ztf_object_path)\n",
    "ztf_object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1594babc-7ce7-4b9c-ae63-424f3e863059",
   "metadata": {},
   "source": [
    "### 1.1. Previewing part of the data\n",
    "\n",
    "Computing an entire catalog requires loading all of its resulting data into memory, which is expensive and may lead to out-of-memory issues. \n",
    "\n",
    "Often, our goal is to have a peek at a slice of data to make sure the workflow output is reasonable (e.g., to assess if some new created columns are present and their values have been properly processed). `head()` is a Pandas-like method which allows us to preview part of the data for this purpose. It iterates over the existing catalog partitions, in sequence, and finds up to `n` number of rows from the first partition(s) which have are able to supply those rows. Related methods include `.tail()` and `.sample()`.\n",
    "\n",
    "There is also `.random_sample()`, but that method fetches rows from many partitions (rather than from first qualified), and so it can be much more expensive, even while it may be more representative.\n",
    "\n",
    "Notice that all these previewing methods implicitly call `compute()`, and will implicitly use the `Client` we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c337414d-9b79-4715-82d1-b10b26472668",
   "metadata": {},
   "outputs": [],
   "source": [
    "ztf_object.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a573c7c",
   "metadata": {},
   "source": [
    "## 2. Selecting data rows by querying column values\n",
    "\n",
    "We can filter by column values via `query()`.\n",
    "\n",
    "The expression in the string given to `.query()` follows the same syntax accepted by Pandas' `.query()`, which supports a subset of Python expressions for filtering DataFrames.\n",
    "\n",
    "The column names that are not valid Python variables names should be wrapped in backticks, and any variable values can be injected using f-strings. The use of '@' to reference variables is not supported.\n",
    "\n",
    "More information about Pandas query strings is available [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html).\n",
    "\n",
    "In the following query, we want to find objects in the catalog whose magnitude is brighter than 16:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf3d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bright = ztf_object.query(\"mean_mag_i < 16\")\n",
    "bright"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb84560-1449-43d1-8939-e974dbe12bb0",
   "metadata": {},
   "source": [
    "We'll use `.head()` for a quick sanity check to be sure that no `mean_mag_i` is dimmer than 16. Since it's only a few rows, it's not a guarantee, but it does help us to be sure that we didn't make any obvious mistake with our query expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5fc9b4-169a-4478-846b-31dd50fba816",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bright.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9d809d-31cc-46ff-b48f-795ba8831340",
   "metadata": {},
   "source": [
    "You can use parentheses, logical operators, and more than one column name in your expressions. Here, we alter the query to include not only those objects with a `mean_mag_i` that is brighter than 16, but which have at least 50 observations in that band. Note that this query takes longer than the original, mostly because it takes longer to find rows that satisfy this stricter query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34db34a-79d0-446c-8702-b86d5c9452ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bright_hi_obs = ztf_object.query(\"mean_mag_i < 16 and nobs_i > 50\")\n",
    "bright_hi_obs.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ca6bb6-172e-4521-b012-fbec8e254b80",
   "metadata": {},
   "source": [
    "## 4. Filtering using Python expressions\n",
    "\n",
    "In some cases it may be more readable to query using Python expressions, Pandas-style. In this form, the catalog is indexed using an expression, selecting the rows for which the expression is true. The form of this query is `filtered = collection[expr_with_collection]`, where `expr_with_collection` needs to evaluate to something which is:\n",
    "\n",
    "  * of the same size as `collection`; and\n",
    "  * convertible to boolean\n",
    "\n",
    "The below expression produces the same result as the earlier `.query()` example, and whether it is more tractable than `.query()` depends on your expression and what it includes. But there are a couple of fixes we need to make, things which `.query()` does for you.\n",
    "\n",
    "  * The use of `&` instead of `and` (also, `|` vs. `or`). The Python logicals don't work here.\n",
    "  * Having to use `(` and `)` to ensure the intended precedence of the operators. (`&` and `|` are bitwise operators and, without parentheses, bind higher than the logical operators `and` and `or`.)\n",
    "\n",
    "Note that the time taken is basically identical to that of the `.query` method. There is no particular performance advantage to either approach, as the underlying computations are vectorized the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c865a480-fefd-4c28-b2fc-d783a27bc62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bright_ex = ztf_object[(ztf_object[\"mean_mag_i\"] < 16) & (ztf_object[\"nobs_i\"] > 50)]\n",
    "bright_ex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb9203-005e-4b68-b3f7-76225cbcbbcb",
   "metadata": {},
   "source": [
    "## Closing the Dask client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b90716-d4b3-4a51-8838-44af2ea89703",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f3b200",
   "metadata": {},
   "source": [
    "## About\n",
    "\n",
    "**Authors**: Sandro Campos, Melissa DeLucchi, Olivia Lynn, and Derek Jones\n",
    "\n",
    "**Last updated on**: April 14, 2025\n",
    "\n",
    "If you use `lsdb` for published research, please cite following [instructions](https://docs.lsdb.io/en/stable/citation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e2002",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
