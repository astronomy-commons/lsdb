{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual catalog verification\n",
    "\n",
    "This notebook presents methods for verifying that a directory contains a valid HATS catalog and performing manual verification through inspecting the catalog metadata and contents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory verification\n",
    "\n",
    "The HATS library provides a method to verify that a directory contains the appropriate metadata files.\n",
    "\n",
    "There are a few flavors of the validation, and the quickest one doesn't take any additional flags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hats.io.validation import is_valid_catalog\n",
    "import hats\n",
    "from upath import UPath\n",
    "\n",
    "gaia_catalog_path = UPath(\"https://data.lsdb.io/hats/gaia_dr3/gaia/\")\n",
    "is_valid_catalog(gaia_catalog_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining the input and output\n",
    "\n",
    "The `strict` argument takes us through a different code path that rigorously tests the contents of all ancillary metadata files and the consistency of the partition pixels.\n",
    "\n",
    "Here, we use the `verbose=True` argument to print out a little bit more information about our catalog. It will repeat the path that we're looking at, display the total number of partitions, and calculate the approximate sky coverage, based on the area of the HATS tiles.\n",
    "\n",
    "The `fail_fast` argument will determine if we break out of the method at the first sign of trouble or keep looking for validation problems. This can be useful if you're debugging multiple points of failure in a catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_valid_catalog(gaia_catalog_path, verbose=True, fail_fast=False, strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns and data types\n",
    "\n",
    "HATS tables are backed by parquet files. These files store metadata about their columns, the data types, and even the range of values.\n",
    "\n",
    "The columns and types are stored on the `catalog.schema` attribute with a `pyarrow.Schema` object. You can find more details on this object and its use [in the pyarrow documents](https://arrow.apache.org/docs/python/generated/pyarrow.Schema.html)\n",
    "\n",
    "Gaia has a lot of columns, so this display is long!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_object = hats.read_hats(gaia_catalog_path)\n",
    "catalog_object.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column statistics\n",
    "\n",
    "Parquet maintains basic statistics about the data inside its files. This includes the minimum value, maximum value, and the number of null (None, or unspecified) rows for that column.\n",
    "\n",
    "We provide a method that consumes all of the min, max, and null counts, and provides global values of min and max, and a total sum of the null counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_object.aggregate_column_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, gaia has a lot of columns. To make the most of this output, you can either use a pandas option to display all of the rows:\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "```\n",
    "\n",
    "Or restrict the columns to those you care about with a keyword argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_object.aggregate_column_statistics(include_columns=[\"ra\", \"dec\", \"ref_epoch\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
