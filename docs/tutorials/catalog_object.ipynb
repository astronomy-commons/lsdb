{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1cb6a4-a0bc-44f2-ae48-d4de23e14c56",
   "metadata": {
    "tags": []
   },
   "source": [
    "# The Catalog Object\n",
    "\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "In this tutorial, you will learn:\n",
    "\n",
    "- The purpose and scope of the `Catalog` object in an LSDB pipeline.\n",
    "- What are lazy operations and how LSDB uses them to run pipelines at scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe8b921",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The `Catalog` object encapsulates all of the information that LSDB knows about an astronomical catalog, and is the basis for performing operations on the underlying catalog data.\n",
    "\n",
    "There are two types of catalog data that the `Catalog` object exposes:\n",
    "1. high-level metadata: The columns and table schema of the catalog, the number of partitions of data, sky coverage, provenance information, basic aggregate statistics about the data.\n",
    "1. leaf-level tabular data: the full rows of data from the objects and/or observations in the catalog.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c3e6d4db2422ff",
   "metadata": {},
   "source": [
    "## 1. Loading a catalog\n",
    "\n",
    "The simplest way to load a catalog in LSDB is to call `lsdb.open_catalog()` with a path to a catalog in the HATS format. This will return a `Catalog` object with all the high level metadata loaded that LSDB needs to enable you to work with the catalog. We recommend you to visit our own website, [data.lsdb.io](https://data.lsdb.io), where you are able to find large surveys in HATS format publicly available to use. Let's open GAIA DR3 as an example and take a look at the object we get back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db61413f40044cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T19:25:52.505340Z",
     "start_time": "2025-06-26T19:25:48.198518Z"
    }
   },
   "outputs": [],
   "source": [
    "import lsdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea1d215bdf1b6aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T19:26:35.996535Z",
     "start_time": "2025-06-26T19:25:54.329199Z"
    }
   },
   "outputs": [],
   "source": [
    "gaia_path = \"https://data.lsdb.io/hats/gaia_dr3\"\n",
    "gaia = lsdb.open_catalog(gaia_path)\n",
    "gaia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b000458e2bdcc31",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Lazy operations\n",
    "\n",
    "When we look at the catalog's representation above, we can see all the columns that are in the catalog object along with their datatypes, and information about how HATS has partitioned the catalog. But there's one thing that we can't see: we haven't loaded any of the data yet! That's why we have the `...` as placeholders for the data, and the warning at the bottom. This is because LSDB's operations are what we call *lazy*: they don't actually perform any work on the data when you call them, they just plan out the pipeline of operations to be performed later. This is how LSDB can work on huge catalogs with billions of rows, and run on any scale of device from a laptop up to a supercomputer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f4941f-8768-48c6-b9ab-bc37846e370c",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<video src=\"../_static/lazy-flowchart.mp4\" loop autoplay controls style=\"width: 100%;\"></video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a8fe6-cffb-4985-9897-1bdaafa473ea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "As explained in the video above, when you call any LSDB operations on the catalog, a task graph is built up - an object that keeps track of the pipeline of operations you want to perform on the catalog. To actually execute the operations, you call the `catalog.compute()` method, which will execute the pipeline and return the resulting data as a pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87189b7b7f34a12",
   "metadata": {},
   "source": [
    "## 2. Inspecting the Catalog metadata\n",
    "\n",
    "The natural next step once you have a catalog object is to explore the metadata that has been loaded to understand what kind of data is inside your catalog.\n",
    "\n",
    "First, we will generate a basic plot showing the sky coverage of the catalog. The `Catalog` object's `plot_pixels` method shows a plot of the HATS partitioning of the catalog. GAIA is a survey that covers the whole sky, so we see the whole sky covered in pixels. The colors of the pixels represent the pixel sizes. The main advantage of HATS partitioning is that the partitions all contain roughly the same amount of rows, so the smaller the pixels, the more dense the catalog is in that area. This explains why we see smaller pixels in the galactic bulge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56edfa5e9f759c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia.plot_pixels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8fe4ee398b13e9",
   "metadata": {},
   "source": [
    "We can also get an idea of the schema of data that's stored in the catalog, by looking at the `columns` and `dtypes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0716511b3352c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621b916f1ff4b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b98e6df1e499ed",
   "metadata": {},
   "source": [
    "We can also see how many objects are in the catalog, which is another piece of metadata that is loaded by `open_catalog`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63beb60431afefbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gaia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d9fd3b-82c3-4f2e-a18c-808f4511c0b4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 3. Operating on the Catalog\n",
    "\n",
    "Once we have a catalog object, we can start planning operations on it. In the rest of the tutorials, we'll look deeper into exactly what kind of operations you can do with a catalog. The catalog is based on pandas `DataFrames` so you'll see some functions that work the same as in pandas, such as `columns`, `dtypes`, `query`, and selecting columns or filtering with `[]`."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8aea7a46-76cb-4f14-8c1f-94ba88c0d07a",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "There are also a lot of astronomy specific functions, such as :doc:`Spatial filters like cone search or box search </tutorials/region_selection>`, and :doc:`Crossmatching </tutorials/pre_executed/crossmatching>`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e0a953-89e3-4708-8d9f-323a2e5cf78d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "After you've performed your operations, you can call `catalog.compute()` to perform the pipeline, but this will run on the entire catalog!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f9188d0ff36119",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 4. Previewing part of the data\n",
    "\n",
    "Computing an entire catalog will result in loading all of its data into memory on your local machine after the workers have computed it, which is expensive and may lead to out-of-memory issues.\n",
    "\n",
    "Often, our goal is to have a peek at a slice of data to make sure the workflow output is reasonable (e.g., to assess if some new created columns are present and their values have been properly processed). `head()` is a pandas-like method which allows us to preview part of the data for this purpose. It runs the pipeline on the catalog partitions one by one, and finds the first few rows of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcc75ac-1cb0-49eb-aac4-7adc6bb57fb4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Making a Dask client\n",
    "\n",
    "LSDB is built on top of the [Dask](https://www.dask.org) framework, which allows the pipelines to be executed on distributed workers. Before we do anything that executes the pipeline such as `head()` or `compute()`, we recommend making a dask client."
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d07448ce129e3de",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "For additional information on dask client creation, please read our tutorial on :doc:`Setting up a Dask Client </tutorials/dask_client>`.\n",
    "\n",
    "For now, we'll make a simple Client that uses 4 workers on our local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fcd614-a797-44cb-8a8c-d4adb30114da",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(n_workers=4, memory_limit=\"auto\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86db85a56712c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b01d143c7a10ac",
   "metadata": {},
   "source": [
    "By default, the first 5 rows of data will be shown, but we can specify a higher number if we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d90c200a8abe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb9203-005e-4b68-b3f7-76225cbcbbcb",
   "metadata": {},
   "source": [
    "### Closing the Dask client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b90716-d4b3-4a51-8838-44af2ea89703",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeaaad6",
   "metadata": {},
   "source": [
    "## About\n",
    "\n",
    "**Authors**: Sandro Campos, Melissa DeLucchi, and Sean McGuire\n",
    "\n",
    "**Last updated on**: Jun 26, 2025\n",
    "\n",
    "If you use `lsdb` for published research, please cite following [instructions](https://docs.lsdb.io/en/stable/citation.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
