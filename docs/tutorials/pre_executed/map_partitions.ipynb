{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b790eee",
   "metadata": {},
   "source": [
    "# Simple Example with map_partitions\n",
    "\n",
    "In this tutorial, we will demonstrate how to perfom a user-defined-function on all partitions of an LSDB catalog.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "LSDB/HATS catalogs are organized into partitions, and this number of partitions is reported as `npartitions=` in the header, whenever printing a catalog.\n",
    "\n",
    "The `map_partitions` method provides a means for users to execute their own analysis functions on each *partition* of the catalog data. The data will be passed to your function as a dataframe.\n",
    "\n",
    "Partitions will be processed in parallel.\n",
    "This can be used to distribute operations across the catalog with maximum efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbecd41",
   "metadata": {},
   "source": [
    "## 1. Load a catalog\n",
    "\n",
    "We will use a small cone of the Gaia DR3 catalog, and only load the columns that we are interested in. This limits the overall memory requirements of the pipeline."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2225843f",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    ".. nbinfo::\n",
    "    Additional Help \n",
    "    \n",
    "    For additional information on dask client creation, please refer to the \n",
    "    `official Dask documentation <https://distributed.dask.org/en/latest/client.html>`__ \n",
    "    and our :doc:`Dask cluster configuration </tutorials/dask-cluster-tips>` page for LSDB-specific tips. \n",
    "    Note that dask also provides its own `best practices <https://docs.dask.org/en/stable/best-practices.html>`__, which may also be useful to consult.\n",
    "    \n",
    "    For tips on accessing remote data, see our :doc:`Accessing remote data tutorial </tutorials/remote_data>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff803be2-c4c9-4bf8-8fe0-5b7e896d6478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask puts out more advisory logging that we care for.\n",
    "# It takes some doing to quiet all of it, but this recipe works.\n",
    "\n",
    "import dask\n",
    "\n",
    "dask.config.set({\"logging.distributed\": \"critical\"})\n",
    "\n",
    "import logging\n",
    "\n",
    "# This also has to be done, for the above to be effective\n",
    "logger = logging.getLogger(\"distributed\")\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Finally, suppress the specific warning about Dask dashboard port usage\n",
    "warnings.filterwarnings(\"ignore\", message=\"Port 8787 is already in use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a21bad26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>lsdb Catalog gaia:</strong></div><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>phot_g_mean_mag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=4</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Order: 4, Pixel: 2944</th>\n",
       "      <td>int64[pyarrow]</td>\n",
       "      <td>double[pyarrow]</td>\n",
       "      <td>double[pyarrow]</td>\n",
       "      <td>double[pyarrow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Order: 4, Pixel: 2945</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Order: 4, Pixel: 2946</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Order: 4, Pixel: 2947</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><div>4 out of 4 columns in the catalog have been loaded <strong>lazily</strong>, meaning no data has been read, only the catalog schema</div>"
      ],
      "text/plain": [
       "Dask NestedFrame Structure:\n",
       "                          source_id               ra              dec  phot_g_mean_mag\n",
       "npartitions=4                                                                         \n",
       "3314649325744685056  int64[pyarrow]  double[pyarrow]  double[pyarrow]  double[pyarrow]\n",
       "3315775225651527680             ...              ...              ...              ...\n",
       "3316901125558370304             ...              ...              ...              ...\n",
       "3318027025465212928             ...              ...              ...              ...\n",
       "3319152925372055552             ...              ...              ...              ...\n",
       "Dask Name: search_points, 5 expressions\n",
       "Expr=MapPartitions(search_points)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lsdb\n",
    "\n",
    "gaia_root = \"https://data.lsdb.io/hats\"\n",
    "gaia3 = lsdb.open_catalog(\n",
    "    f\"{gaia_root}/gaia_dr3/gaia\",\n",
    "    margin_cache=f\"{gaia_root}/gaia_dr3/gaia_10arcs\",\n",
    "    search_filter=lsdb.ConeSearch(ra=280, dec=-60, radius_arcsec=2 * 3600),\n",
    "    columns=[\n",
    "        \"source_id\",\n",
    "        \"ra\",\n",
    "        \"dec\",\n",
    "        \"phot_g_mean_mag\",\n",
    "    ],\n",
    ")\n",
    "gaia3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7276c506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can get the number of partitions programmatically this way.\n",
    "# This can be valuable when you want to choose the optimal number\n",
    "# of workers to process the partitions.\n",
    "gaia3.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc88d6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(4), np.int64(2944))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also access the individual HealpixPixel objects for\n",
    "# each partition, this way, inspecting their order and pixel,\n",
    "# if desired.\n",
    "px = gaia3.get_healpix_pixels()[0]\n",
    "px.order, px.pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036d0560",
   "metadata": {},
   "source": [
    "## 2. Generating New Columns\n",
    "\n",
    "Since the partition's `DataFrame` is passed in to your custom function, you can augment it with new columns based on the existing columns, in ordinary Pandas style.\n",
    "\n",
    "### 2.1 What you can map\n",
    "\n",
    "The trick is understanding what kind of custom function you can pass to `.map_partitions`.  Your function is going to receive a Pandas DataFrame as its first parameter.  Other parameters can be passed in as keyword arguments to `.map_partitions`, as you'll see later on.  For now, we'll use a function that takes in one partition and produces a result that has the same shape.\n",
    "\n",
    "Because the catalog is loaded lazily, `.map_partitions` also returns a lazy, or unevaluated, result.  You can see the results the same way you can realize the original catalog, by any of these means:\n",
    "  * calling `.compute()` to produce a `DataFrame` in memory;\n",
    "  * calling `.to_hats()` to serialize it to disk as a HATS-format file;\n",
    "  * calling `.head()` to see the first few rows, `.tail()` to see the last few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fe9acfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>lsdb Catalog gaia:</strong></div><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>phot_g_mean_mag</th>\n",
       "      <th>phot_g_mean_mag_sq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=4</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Order: 4, Pixel: 2944</th>\n",
       "      <td>int64[pyarrow]</td>\n",
       "      <td>double[pyarrow]</td>\n",
       "      <td>double[pyarrow]</td>\n",
       "      <td>double[pyarrow]</td>\n",
       "      <td>double[pyarrow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Order: 4, Pixel: 2945</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Order: 4, Pixel: 2946</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Order: 4, Pixel: 2947</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><div>5 out of 5 columns in the catalog have been loaded <strong>lazily</strong>, meaning no data has been read, only the catalog schema</div>"
      ],
      "text/plain": [
       "Dask NestedFrame Structure:\n",
       "                          source_id               ra              dec  phot_g_mean_mag phot_g_mean_mag_sq\n",
       "npartitions=4                                                                                            \n",
       "3314649325744685056  int64[pyarrow]  double[pyarrow]  double[pyarrow]  double[pyarrow]    double[pyarrow]\n",
       "3315775225651527680             ...              ...              ...              ...                ...\n",
       "3316901125558370304             ...              ...              ...              ...                ...\n",
       "3318027025465212928             ...              ...              ...              ...                ...\n",
       "3319152925372055552             ...              ...              ...              ...                ...\n",
       "Dask Name: nestedframe, 7 expressions\n",
       "Expr=MapPartitions(NestedFrame)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_sq(df, pixel):\n",
    "    df[\"phot_g_mean_mag_sq\"] = df[\"phot_g_mean_mag\"] ** 2\n",
    "    return df\n",
    "\n",
    "\n",
    "unrealized = gaia3.map_partitions(mean_sq, include_pixel=True)\n",
    "unrealized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b439ab-5845-4090-8350-109e59775d5e",
   "metadata": {},
   "source": [
    "Taking a quick peek to see whether our function works correctly, and if the results in our new column are about what we expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "884233a7-b6ef-47d7-aa38-30a48d19f77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>phot_g_mean_mag</th>\n",
       "      <th>phot_g_mean_mag_sq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_healpix_29</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3315212135629220059</th>\n",
       "      <td>6630424242158614528</td>\n",
       "      <td>279.475941</td>\n",
       "      <td>-61.973682</td>\n",
       "      <td>20.157476</td>\n",
       "      <td>406.323839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315212197603296958</th>\n",
       "      <td>6630424379597543936</td>\n",
       "      <td>279.40738</td>\n",
       "      <td>-61.977054</td>\n",
       "      <td>19.488537</td>\n",
       "      <td>379.803074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315212213755151065</th>\n",
       "      <td>6630424413957281792</td>\n",
       "      <td>279.436314</td>\n",
       "      <td>-61.979345</td>\n",
       "      <td>18.925087</td>\n",
       "      <td>358.158918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315212218438134563</th>\n",
       "      <td>6630424418254234752</td>\n",
       "      <td>279.412417</td>\n",
       "      <td>-61.979072</td>\n",
       "      <td>20.522877</td>\n",
       "      <td>421.18848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315212218704706046</th>\n",
       "      <td>6630424418256341376</td>\n",
       "      <td>279.416172</td>\n",
       "      <td>-61.977445</td>\n",
       "      <td>16.336718</td>\n",
       "      <td>266.888355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5 columns</p>"
      ],
      "text/plain": [
       "                               source_id          ra        dec  \\\n",
       "_healpix_29                                                       \n",
       "3315212135629220059  6630424242158614528  279.475941 -61.973682   \n",
       "3315212197603296958  6630424379597543936   279.40738 -61.977054   \n",
       "3315212213755151065  6630424413957281792  279.436314 -61.979345   \n",
       "3315212218438134563  6630424418254234752  279.412417 -61.979072   \n",
       "3315212218704706046  6630424418256341376  279.416172 -61.977445   \n",
       "\n",
       "                     phot_g_mean_mag  phot_g_mean_mag_sq  \n",
       "_healpix_29                                               \n",
       "3315212135629220059        20.157476          406.323839  \n",
       "3315212197603296958        19.488537          379.803074  \n",
       "3315212213755151065        18.925087          358.158918  \n",
       "3315212218438134563        20.522877           421.18848  \n",
       "3315212218704706046        16.336718          266.888355  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unrealized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16fa7e9-2fc3-4e26-89aa-cf050493e363",
   "metadata": {},
   "source": [
    "Looks good! Now on to computing the complete result.\n",
    "\n",
    "This unrealized result has a top-level property indicating how many partitions it has.  We can use this to choose our number of workers directly.\n",
    "\n",
    "However, it's a good idea to bound the number of workers, in case the number of partitions is larger than we expect (or we move this code fragment elsewhere)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb04c74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.24 s, sys: 846 ms, total: 2.09 s\n",
      "Wall time: 23.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>phot_g_mean_mag</th>\n",
       "      <th>phot_g_mean_mag_sq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_healpix_29</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3315212135629220059</th>\n",
       "      <td>6630424242158614528</td>\n",
       "      <td>279.475941</td>\n",
       "      <td>-61.973682</td>\n",
       "      <td>20.157476</td>\n",
       "      <td>406.323839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315212197603296958</th>\n",
       "      <td>6630424379597543936</td>\n",
       "      <td>279.40738</td>\n",
       "      <td>-61.977054</td>\n",
       "      <td>19.488537</td>\n",
       "      <td>379.803074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318663093295462547</th>\n",
       "      <td>6637326190180387584</td>\n",
       "      <td>280.426265</td>\n",
       "      <td>-58.015067</td>\n",
       "      <td>21.097507</td>\n",
       "      <td>445.104802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318663093808668415</th>\n",
       "      <td>6637326185883831296</td>\n",
       "      <td>280.423503</td>\n",
       "      <td>-58.013744</td>\n",
       "      <td>20.301455</td>\n",
       "      <td>412.149075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469102 rows × 5 columns</p>"
      ],
      "text/plain": [
       "                               source_id          ra        dec  \\\n",
       "_healpix_29                                                       \n",
       "3315212135629220059  6630424242158614528  279.475941 -61.973682   \n",
       "3315212197603296958  6630424379597543936   279.40738 -61.977054   \n",
       "...                                  ...         ...        ...   \n",
       "3318663093295462547  6637326190180387584  280.426265 -58.015067   \n",
       "3318663093808668415  6637326185883831296  280.423503 -58.013744   \n",
       "\n",
       "                     phot_g_mean_mag  phot_g_mean_mag_sq  \n",
       "_healpix_29                                               \n",
       "3315212135629220059        20.157476          406.323839  \n",
       "3315212197603296958        19.488537          379.803074  \n",
       "...                              ...                 ...  \n",
       "3318663093295462547        21.097507          445.104802  \n",
       "3318663093808668415        20.301455          412.149075  \n",
       "\n",
       "[469102 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "npartitions = gaia3.npartitions\n",
    "from dask.distributed import Client\n",
    "\n",
    "with Client(n_workers=min(8, npartitions)) as client:\n",
    "    result = unrealized.compute()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb134afe",
   "metadata": {},
   "source": [
    "No reduction step is needed here since the operation is not a reducing operation.\n",
    "There are as many rows in the new output as there were in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa390b4-cf26-4d69-aaeb-525979f79bc7",
   "metadata": {},
   "source": [
    "## 3. Functions that reduce\n",
    "\n",
    "The above works when your output rows are the same as your input rows.  When you're doing a reducing operation (such as calculating statistics), the process changes a little."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17ae459",
   "metadata": {},
   "source": [
    "### 3.1. Your function's parameters\n",
    "\n",
    "Again, your first input parameter is a `pd.DataFrame` that is one partition of the catalog, and the return value of your function needs to be the same, even if your result has only a single row.\n",
    "\n",
    "If you want to know the HEALPix number of the partition, calling `.map_partitions` with `include_pixel=True` will pass that as the second parameter to your function.  We'll do this in this example, for demonstration purposes, though it isn't strictly necessary to this task.\n",
    "\n",
    "If you have any other parameters that your function requires, take them as keyword arguments, and you can pass their values in as such, when calling `.map_partitions`.  Our example will do this, too, taking a `target_column=` argument.\n",
    "\n",
    "### 3.2. What you get back\n",
    "\n",
    "The operation we're going to do here is a reducing operation (min and max), and it will be run on each partition, reducing the many rows in each partition to a single value.  This means that the output of `.map_partitions` in this case will contain *one row per partition*.  Thus, you will need to do additional reduction on this output in order to get a single final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e216f1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this function must work correctly when given an empty DataFrame\n",
    "# as an input, too; if not, you're obliged to provide \"meta\", that is,\n",
    "# information about output type and shape.\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def find_stats(df, pixel, target_column=\"\"):\n",
    "    c = df[target_column]\n",
    "    min_val = c.min()\n",
    "    max_val = c.max()\n",
    "    mean_val = c.mean()\n",
    "    return pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"pixel\": pixel,\n",
    "                f\"{target_column}_min\": min_val,\n",
    "                f\"{target_column}_max\": max_val,\n",
    "                f\"{target_column}_mean\": mean_val,\n",
    "            }\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea19896-60e7-41c7-9886-29bcb2e91543",
   "metadata": {},
   "source": [
    "### 3.3 When You Need `meta=`\n",
    "\n",
    "The above definition of `find_stats` works even with an empty `DataFrame` argument because `.mean()` is written to handle zero-row inputs without errors.\n",
    "\n",
    "But your own custom function might not. As a trivial example, suppose you implemented the arithmetic mean yourself, as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b75bd821-ed54-49a7-8833-7b842077ab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This version of the function will NOT work with map_partitions as is, because\n",
    "# of the attempt to divide by `c.count()`, which will be zero for an empty input.\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def find_stats_needs_meta(df, pixel, target_column=\"\"):\n",
    "    c = df[target_column]\n",
    "    min_val = c.min()\n",
    "    max_val = c.max()\n",
    "    # WARNING! c.count() == 0 when passed an empty DataFrame.\n",
    "    # But meta= will come to the rescue.\n",
    "    mean_val = c.sum() / c.count()\n",
    "    return pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"pixel\": pixel,\n",
    "                f\"{target_column}_min\": min_val,\n",
    "                f\"{target_column}_max\": max_val,\n",
    "                f\"{target_column}_mean\": mean_val,\n",
    "            }\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c52776-2a83-49a6-97a2-1b8efc21f3fc",
   "metadata": {},
   "source": [
    "In the above case, then, you need to indicate to Dask what type the output will be.\n",
    "\n",
    "What Dask needs to know are the column names and their order, and so the below definition works, even though the types of the columns aren't indicated. (The type of `\"pixel\"` will default to `float64`, which is wrong, but doesn't matter in this case.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da7d89aa-e24a-4858-8ec0-e0a54a6db1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_meta = pd.DataFrame(\n",
    "    {\n",
    "        \"pixel\": [],\n",
    "        \"phot_g_mean_mag_min\": [],\n",
    "        \"phot_g_mean_mag_max\": [],\n",
    "        \"phot_g_mean_mag_mean\": [],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee5f86-8b4e-4bfd-a39b-30332b83071b",
   "metadata": {},
   "source": [
    "Here's another definition of `output_meta` that works equally well. The type of `\"pixel\"` will now be more correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b5bcbd9-a28c-4ada-ac58-76513f20ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_meta = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"pixel\": lsdb.HealpixPixel(0, 0),\n",
    "            \"phot_g_mean_mag_min\": 0.0,\n",
    "            \"phot_g_mean_mag_max\": 0.0,\n",
    "            \"phot_g_mean_mag_mean\": 0.0,\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24f497d9-8b44-4299-8831-5fff6abfdd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_meta[\"pixel\"].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790832fe-e8cc-43e6-985a-82292e763961",
   "metadata": {},
   "source": [
    "although `DataFrame` only cares that it is an \"Object\", as we can see."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c00bfb-8aec-40c8-a79a-784b15c03dde",
   "metadata": {},
   "source": [
    "These can be complicated and error-prone to construct, and small mistakes create confusing errors that show up late in the computation.\n",
    "\n",
    "To help with these difficulties, Dask does provide a `make_meta` function. If you can pass it a single valid row from your catalog (that's what `.head(1)` will do) which will work with your custom function, `make_meta` will generate the meta for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7264ec2c-4b38-4b76-be9f-da6ef2dee5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.dataframe.utils import make_meta\n",
    "\n",
    "output_meta = make_meta(\n",
    "    find_stats(gaia3.head(1), gaia3.get_healpix_pixels()[0], target_column=\"phot_g_mean_mag\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d323fc0f-7cef-40f1-a37f-2fa7fb9c38df",
   "metadata": {},
   "source": [
    "Passing a correct `meta=` to `.map_partitions` will allow Dask to skip sending your function an empty `DataFrame`, and so, in our case of `find_stats_needs_meta` (where we depend on a non-zero `c.count()`), it will succeed without error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30ec3bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unrealized = gaia3.map_partitions(\n",
    "    find_stats_needs_meta,\n",
    "    include_pixel=True,\n",
    "    # Keyword arguments after 'include_pixel=' are passed to your function.\n",
    "    target_column=\"phot_g_mean_mag\",\n",
    "    # Here we give Dask the hint it needs to avoid giving us an empty frame\n",
    "    meta=output_meta,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51dc5f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 772 ms, sys: 674 ms, total: 1.45 s\n",
      "Wall time: 22.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel</th>\n",
       "      <th>phot_g_mean_mag_min</th>\n",
       "      <th>phot_g_mean_mag_max</th>\n",
       "      <th>phot_g_mean_mag_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Order: 4, Pixel: 2944</td>\n",
       "      <td>8.154537</td>\n",
       "      <td>22.033451</td>\n",
       "      <td>19.083840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Order: 4, Pixel: 2945</td>\n",
       "      <td>5.508409</td>\n",
       "      <td>22.345750</td>\n",
       "      <td>19.094207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Order: 4, Pixel: 2946</td>\n",
       "      <td>6.264917</td>\n",
       "      <td>22.076380</td>\n",
       "      <td>19.102860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Order: 4, Pixel: 2947</td>\n",
       "      <td>6.154421</td>\n",
       "      <td>21.986425</td>\n",
       "      <td>19.119143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 4 columns</p>"
      ],
      "text/plain": [
       "                   pixel  phot_g_mean_mag_min  phot_g_mean_mag_max  \\\n",
       "0  Order: 4, Pixel: 2944             8.154537            22.033451   \n",
       "0  Order: 4, Pixel: 2945             5.508409            22.345750   \n",
       "0  Order: 4, Pixel: 2946             6.264917            22.076380   \n",
       "0  Order: 4, Pixel: 2947             6.154421            21.986425   \n",
       "\n",
       "   phot_g_mean_mag_mean  \n",
       "0             19.083840  \n",
       "0             19.094207  \n",
       "0             19.102860  \n",
       "0             19.119143  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "npartitions = gaia3.npartitions\n",
    "from dask.distributed import Client\n",
    "\n",
    "with Client(n_workers=min(8, npartitions)) as client:\n",
    "    result = unrealized.compute()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc892c79-0217-41f5-b5f0-2b04adb521e4",
   "metadata": {},
   "source": [
    "The objects in the 'pixel' column are the same type as from `get_healpix_pixels()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67458c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hats.pixel_math.healpix_pixel.HealpixPixel"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result[\"pixel\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f2e7ae-b726-45f8-85f1-585ce9844450",
   "metadata": {},
   "source": [
    "Because the result is one row per partition, we need additional reduction to get our single answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f82b3a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(5.508409), np.float64(22.34575), np.float64(19.100012538364453))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"phot_g_mean_mag_min\"].min(), result[\"phot_g_mean_mag_max\"].max(), result[\n",
    "    \"phot_g_mean_mag_mean\"\n",
    "].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bca02ea-4d18-4eaa-b58f-6406b456eb9c",
   "metadata": {},
   "source": [
    "What about searching not only the four partitions from our cone search, but the whole catalog?  All that changes is the number of partitions.\n",
    "\n",
    "**NOTE** that since we're using the `find_stats` that doesn't need `meta=`, we don't need to provide it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5ce67d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia3_all = lsdb.open_catalog(\n",
    "    f\"{gaia_root}/gaia_dr3/gaia\",\n",
    "    margin_cache=f\"{gaia_root}/gaia_dr3/gaia_10arcs\",\n",
    "    columns=[\n",
    "        \"source_id\",\n",
    "        \"ra\",\n",
    "        \"dec\",\n",
    "        \"phot_g_mean_mag\",\n",
    "    ],\n",
    ")\n",
    "unrealized = gaia3_all.map_partitions(\n",
    "    find_stats,\n",
    "    include_pixel=True,\n",
    "    # Keyword arguments after 'include_pixel=' are passed to your\n",
    "    # function\n",
    "    target_column=\"phot_g_mean_mag\",\n",
    ")\n",
    "npartitions = unrealized.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c41f0150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3933"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf33d66f-0a7f-4238-80f3-51d439b076e4",
   "metadata": {},
   "source": [
    "That's a lot of partitions!  If we didn't bound this value, we could easily overwhelm our cluster.\n",
    "\n",
    "This operation is light on compute, so let's give each worker several threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6774bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 17:25:02,780 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.62 GiB -- Worker memory limit: 3.73 GiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with Client(n_workers=min(8, npartitions), memory_limit=\"4GB\", threads_per_worker=4) as client:\n",
    "    result = unrealized.compute()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568ed81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to do a final reduction step to get the true min and max\n",
    "result[\"phot_g_mean_mag_min\"].min(), result[\"phot_g_mean_mag_max\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4b0c69-cf65-4066-bbc7-662219e46085",
   "metadata": {},
   "source": [
    "Since we just searched the whole catalog, we can check our answer\n",
    "against the statistics that were compiled at import time for the\n",
    "catalog.  As you can see, they match what we got when using\n",
    "the `.map_partitions` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f919773",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia3_all.hc_structure.aggregate_column_statistics(include_columns=\"phot_g_mean_mag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae086b8",
   "metadata": {},
   "source": [
    "## 4. Histograms\n",
    "\n",
    "Here's another example that requires a reduction and a change\n",
    "in data shape.\n",
    "\n",
    "Suppose we want to bin observations by magnitude in the G band.\n",
    "We'll need to load different columns than before,\n",
    "since we didn't include observations earlier.\n",
    "\n",
    "This is more involved than the straightforward `pd.DataFrame.hist`\n",
    "because each row contains some number of observations, and we want\n",
    "to sum these observations within each magnitude bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57245970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsdb\n",
    "\n",
    "gaia3 = lsdb.open_catalog(\n",
    "    f\"{gaia_root}/gaia_dr3/gaia\",\n",
    "    margin_cache=f\"{gaia_root}/gaia_dr3/gaia_10arcs\",\n",
    "    search_filter=lsdb.ConeSearch(ra=280, dec=-60, radius_arcsec=2 * 3600),\n",
    "    columns=[\n",
    "        \"source_id\",\n",
    "        \"ra\",\n",
    "        \"dec\",\n",
    "        \"phot_g_mean_mag\",\n",
    "        \"phot_g_n_obs\",\n",
    "    ],\n",
    ")\n",
    "gaia3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902edefb",
   "metadata": {},
   "source": [
    "### 4.1. All Within Memory\n",
    "\n",
    "First, what does it look like to do it all within memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4029e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = gaia3.compute()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805e0198",
   "metadata": {},
   "source": [
    "Note that the four partitions become over 450k rows once they are computed.  The lazily-loaded\n",
    "catalog can't show you how many total rows there are before computing, only the number of\n",
    "partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492c745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "mag_bins = list(range(5, 25, 1))\n",
    "plt.hist(df[\"phot_g_mean_mag\"], bins=mag_bins, weights=df[\"phot_g_n_obs\"])\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b5a12",
   "metadata": {},
   "source": [
    "This is a small enough amount of data that it's easy to handle it\n",
    "in-memory.  But we wouldn't be able to do this on the whole Gaia3\n",
    "catalog.  For that, we'll need to use `.map_partitions`, and we'll\n",
    "test this function on the same small piece of data before launching\n",
    "it across the entire catalog.\n",
    "\n",
    "The first step is to understand that we'll be creating partial histograms,\n",
    "that is, a histogram for each partition, and we'll need to reduce those\n",
    "down to a single histogram at the end.  One consequence of this is\n",
    "the need to have the same number of bins in each partial histogram,\n",
    "`mag_bins` in this case.  Often when producing a histogram, it's common\n",
    "to let Pandas or `pd.cut` pick the bin boundaries given a number of\n",
    "bins, but that will work against us in this case, since each partition\n",
    "will have a different min and max, and the partial histograms won't\n",
    "reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe6fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function only requires and returns one DataFrame: no pixel\n",
    "# argument, no additional arguments.\n",
    "def observation_histogram(df):\n",
    "    df[\"binned\"] = pd.cut(df[\"phot_g_mean_mag\"], mag_bins)\n",
    "    binned_data = df.groupby(\"binned\", observed=True)[\"phot_g_n_obs\"].sum()\n",
    "    return pd.DataFrame(binned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b924be",
   "metadata": {},
   "source": [
    "First, we test our new function on our single in-memory `DataFrame`, to\n",
    "see that we get the results we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae913148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "bd = observation_histogram(df)\n",
    "\n",
    "bd.plot(kind=\"bar\", ax=ax, label=\"Observations\")\n",
    "\n",
    "ax.set_title(\"Histogram of Detections by Magnitude Bins\")\n",
    "ax.set_xlabel(\"G Band Magnitudes\")\n",
    "ax.set_ylabel(\"Total Sources\")\n",
    "\n",
    "ax.legend()\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3eca1c",
   "metadata": {},
   "source": [
    "### 4.2. Using map_partitions\n",
    "\n",
    "The above went pretty quickly, because our cone search is keeping our data small.\n",
    "But if it were a much larger slice of the sky, this next technique would matter\n",
    "more.\n",
    "\n",
    "As before, `.map_partitions` will give us one result per partition, so we need\n",
    "to be prepared to do a final combination step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7095533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unrealized = gaia3.map_partitions(observation_histogram)\n",
    "unrealized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5377055",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "npartitions = unrealized.npartitions\n",
    "from dask.distributed import Client\n",
    "\n",
    "with Client(n_workers=min(8, npartitions)) as client:\n",
    "    result = unrealized.compute()\n",
    "# This is actually the histogram repeated for each partition.\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6f9393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final reduction step\n",
    "total_histogram = result.groupby(\"binned\", observed=True).sum()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "total_histogram.plot(kind=\"bar\", ax=ax)\n",
    "ax.set_title(\"Histogram of Detections by Magnitude\")\n",
    "ax.set_xlabel(\"G Band Magnitude\")\n",
    "ax.set_ylabel(\"Sum of Detections\")\n",
    "ax.set_yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ddb7c",
   "metadata": {},
   "source": [
    "And now compare the result and timing to running this histogram on\n",
    "the entire catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c22a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia3 = lsdb.open_catalog(\n",
    "    f\"{gaia_root}/gaia_dr3/gaia\",\n",
    "    margin_cache=f\"{gaia_root}/gaia_dr3/gaia_10arcs\",\n",
    "    columns=[\n",
    "        \"source_id\",\n",
    "        \"ra\",\n",
    "        \"dec\",\n",
    "        \"phot_g_mean_mag\",\n",
    "        \"phot_g_n_obs\",\n",
    "    ],\n",
    ")\n",
    "unrealized = gaia3.map_partitions(observation_histogram)\n",
    "unrealized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85d63f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "npartitions = unrealized.npartitions\n",
    "from dask.distributed import Client\n",
    "\n",
    "# Takes 8-10 minutes\n",
    "with Client(n_workers=min(8, npartitions), threads_per_worker=4) as client:\n",
    "    result = unrealized.compute()\n",
    "# This is actually the histogram repeated for each partition.\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5360fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final reduction\n",
    "total_histogram = result.groupby(\"binned\", observed=True).sum()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "total_histogram.plot(kind=\"bar\", ax=ax)\n",
    "ax.set_title(\"Histogram of Detections by Magnitude\")\n",
    "ax.set_xlabel(\"G Band Magnitude\")\n",
    "ax.set_ylabel(\"Sum of Detections\")\n",
    "ax.set_yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d8d294",
   "metadata": {},
   "source": [
    "The histogram has the same shape but a different Y-axis, as is reasonable:\n",
    "our small cone search had picked a part of the sky which was representative\n",
    "of the whole, but processing the entire catalog increased the number\n",
    "of observations across all bins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0726ac",
   "metadata": {},
   "source": [
    "## About\n",
    "\n",
    "**Authors**: Derek Jones\n",
    "\n",
    "**Last updated on**: April 17, 2025\n",
    "\n",
    "If you use `lsdb` for published research, please cite following [instructions](https://docs.lsdb.io/en/stable/citation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220b7c5e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
