{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaad3391",
   "metadata": {},
   "source": [
    "# Determining the Right Dask Cluster Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15f9b56",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "In this tutorial, we will:\n",
    "* Show how to configure clusters based on the memory demands of larger data partitions\n",
    "* Show how to find the largest data partitions in a dataset\n",
    "* Discuss general strategies for scaling in-memory code to large out-of-memory runs\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Working at scale almost always demands that you, the user, understand details of your workflows memory usage to properly setup the various parameters of your cluster setup. This can also be a very challenging task, as many users are not used to being aware of how much memory their code needs to execute. In this tutorial, we'll walk through a few strategies for determining how much memory your workers will need in the \"worst case\" and try to equip you with some code and hueristics for how to think about setting up a cluster for your workflow.\n",
    "\n",
    "Install external packages needed for this notebook with the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c69f13f-5c01-463e-9a59-e7ef0d9150b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install light-curve memory-profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65754145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsdb\n",
    "import light_curve as licu\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245d4ead",
   "metadata": {},
   "source": [
    "For this tutorial, we'll be looking at ZTF DR22. The first thing we'll do, is find the largest pixel (not by spatial size, but by the amount of data stored within it)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de2100e",
   "metadata": {},
   "source": [
    "Finding the largest pixel can be really helpful setting our cluster up for success, as it will usually be the most challenging partition for a worker to handle. Below, we compute per_pixel_statistics for the catalog, and display the top 5 largest pixels by nested row_count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "497c86b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectid: row_count</th>\n",
       "      <th>hmjd: row_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Order: 5, Pixel: 7457</th>\n",
       "      <td>911483.0</td>\n",
       "      <td>327483964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Order: 5, Pixel: 7460</th>\n",
       "      <td>888057.0</td>\n",
       "      <td>308832839.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Order: 6, Pixel: 14533</th>\n",
       "      <td>950980.0</td>\n",
       "      <td>304487284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Order: 6, Pixel: 30526</th>\n",
       "      <td>984845.0</td>\n",
       "      <td>302272221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Order: 6, Pixel: 29868</th>\n",
       "      <td>931536.0</td>\n",
       "      <td>300487880.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        objectid: row_count  hmjd: row_count\n",
       "Order: 5, Pixel: 7457              911483.0      327483964.0\n",
       "Order: 5, Pixel: 7460              888057.0      308832839.0\n",
       "Order: 6, Pixel: 14533             950980.0      304487284.0\n",
       "Order: 6, Pixel: 30526             984845.0      302272221.0\n",
       "Order: 6, Pixel: 29868             931536.0      300487880.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ztf_cat = lsdb.open_catalog(\"https://data.lsdb.io/hats/ztf_dr22\")\n",
    "stats = ztf_cat.per_pixel_statistics(include_columns=[\"objectid\", \"hmjd\"], include_stats=[\"row_count\"])\n",
    "stats.sort_values([\"hmjd: row_count\"], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4567b1",
   "metadata": {},
   "source": [
    "Some of our largest partitions in this dataset have just shy of a million objects, with 300 million timeseries observations for them in total. Let's grab one of them into memory, by searching for it via `PixelSearch` and then using `compute`. We can work with this partition locally, as a means to directly develop and test our analysis code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b4bf07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ff1db\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ff1db_level0_col0\" class=\"col_heading level0 col0\" >objectid</th>\n",
       "      <th id=\"T_ff1db_level0_col1\" class=\"col_heading level0 col1\" >filterid</th>\n",
       "      <th id=\"T_ff1db_level0_col2\" class=\"col_heading level0 col2\" >objra</th>\n",
       "      <th id=\"T_ff1db_level0_col3\" class=\"col_heading level0 col3\" >objdec</th>\n",
       "      <th id=\"T_ff1db_level0_col4\" class=\"col_heading level0 col4\" >nepochs</th>\n",
       "      <th id=\"T_ff1db_level0_col5\" class=\"col_heading level0 col5\" >lc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ff1db_level0_row0\" class=\"row_heading level0 row0\" >2098958901716483082</th>\n",
       "      <td id=\"T_ff1db_row0_col0\" class=\"data row0 col0\" >385202300127741</td>\n",
       "      <td id=\"T_ff1db_row0_col1\" class=\"data row0 col1\" >2</td>\n",
       "      <td id=\"T_ff1db_row0_col2\" class=\"data row0 col2\" >288.283020</td>\n",
       "      <td id=\"T_ff1db_row0_col3\" class=\"data row0 col3\" >-13.245409</td>\n",
       "      <td id=\"T_ff1db_row0_col4\" class=\"data row0 col4\" >780</td>\n",
       "      <td id=\"T_ff1db_row0_col5\" class=\"data row0 col5\" ><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>hmjd</th>\n",
       "      <th>mag</th>\n",
       "      <th>magerr</th>\n",
       "      <th>clrcoeff</th>\n",
       "      <th>catflags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>58246.45959</td>\n",
       "      <td>18.74802</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.101397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 5 columns</p></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff1db_level0_row1\" class=\"row_heading level0 row1\" >2098958901716483896</th>\n",
       "      <td id=\"T_ff1db_row1_col0\" class=\"data row1 col0\" >385102300097293</td>\n",
       "      <td id=\"T_ff1db_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "      <td id=\"T_ff1db_row1_col2\" class=\"data row1 col2\" >288.283020</td>\n",
       "      <td id=\"T_ff1db_row1_col3\" class=\"data row1 col3\" >-13.245406</td>\n",
       "      <td id=\"T_ff1db_row1_col4\" class=\"data row1 col4\" >213</td>\n",
       "      <td id=\"T_ff1db_row1_col5\" class=\"data row1 col5\" ><table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>58246.46433</td>\n",
       "      <td>19.302635</td>\n",
       "      <td>0.068967</td>\n",
       "      <td>-0.020058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213 rows × 5 columns</p></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff1db_level0_row2\" class=\"row_heading level0 row2\" >2098958901746886855</th>\n",
       "      <td id=\"T_ff1db_row2_col0\" class=\"data row2 col0\" >385202300096509</td>\n",
       "      <td id=\"T_ff1db_row2_col1\" class=\"data row2 col1\" >2</td>\n",
       "      <td id=\"T_ff1db_row2_col2\" class=\"data row2 col2\" >288.281982</td>\n",
       "      <td id=\"T_ff1db_row2_col3\" class=\"data row2 col3\" >-13.245864</td>\n",
       "      <td id=\"T_ff1db_row2_col4\" class=\"data row2 col4\" >955</td>\n",
       "      <td id=\"T_ff1db_row2_col5\" class=\"data row2 col5\" ><table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>58246.45959</td>\n",
       "      <td>16.59124</td>\n",
       "      <td>0.015825</td>\n",
       "      <td>0.101397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>955 rows × 5 columns</p></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff1db_level0_row3\" class=\"row_heading level0 row3\" >2098958901746923271</th>\n",
       "      <td id=\"T_ff1db_row3_col0\" class=\"data row3 col0\" >385102300085934</td>\n",
       "      <td id=\"T_ff1db_row3_col1\" class=\"data row3 col1\" >1</td>\n",
       "      <td id=\"T_ff1db_row3_col2\" class=\"data row3 col2\" >288.281982</td>\n",
       "      <td id=\"T_ff1db_row3_col3\" class=\"data row3 col3\" >-13.245849</td>\n",
       "      <td id=\"T_ff1db_row3_col4\" class=\"data row3 col4\" >298</td>\n",
       "      <td id=\"T_ff1db_row3_col5\" class=\"data row3 col5\" ><table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>58234.40196</td>\n",
       "      <td>17.127243</td>\n",
       "      <td>0.021141</td>\n",
       "      <td>-0.01969</td>\n",
       "      <td>32768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298 rows × 5 columns</p></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff1db_level0_row4\" class=\"row_heading level0 row4\" >2098958901946483197</th>\n",
       "      <td id=\"T_ff1db_row4_col0\" class=\"data row4 col0\" >385202300139959</td>\n",
       "      <td id=\"T_ff1db_row4_col1\" class=\"data row4 col1\" >2</td>\n",
       "      <td id=\"T_ff1db_row4_col2\" class=\"data row4 col2\" >288.280243</td>\n",
       "      <td id=\"T_ff1db_row4_col3\" class=\"data row4 col3\" >-13.245934</td>\n",
       "      <td id=\"T_ff1db_row4_col4\" class=\"data row4 col4\" >1</td>\n",
       "      <td id=\"T_ff1db_row4_col5\" class=\"data row4 col5\" ><table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>58716.21867</td>\n",
       "      <td>21.299936</td>\n",
       "      <td>0.219311</td>\n",
       "      <td>0.088564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 5 columns</p></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"row_heading level0 row_trim\" >...</th>\n",
       "      <td class=\"data col0 row_trim\" >...</td>\n",
       "      <td class=\"data col1 row_trim\" >...</td>\n",
       "      <td class=\"data col2 row_trim\" >...</td>\n",
       "      <td class=\"data col3 row_trim\" >...</td>\n",
       "      <td class=\"data col4 row_trim\" >...</td>\n",
       "      <td class=\"data row_trim col_trim\" >...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "921107 rows x 6 columns"
      ],
      "text/plain": [
       "                            objectid  filterid       objra     objdec  \\\n",
       "_healpix_29                                                             \n",
       "2098958901716483082  385202300127741         2   288.28302 -13.245409   \n",
       "2098958901716483896  385102300097293         1   288.28302 -13.245406   \n",
       "...                              ...       ...         ...        ...   \n",
       "2099240375263563088  385206300108548         2  288.281403 -10.810977   \n",
       "2099240376120221204  385206200143962         2  288.281952 -10.808293   \n",
       "\n",
       "                     nepochs  \\\n",
       "_healpix_29                    \n",
       "2098958901716483082      780   \n",
       "2098958901716483896      213   \n",
       "...                      ...   \n",
       "2099240375263563088       67   \n",
       "2099240376120221204        3   \n",
       "\n",
       "                                                                    lc  \n",
       "_healpix_29                                                             \n",
       "2098958901716483082  [{hmjd: 58246.45959, mag: 18.74802, magerr: 0....  \n",
       "2098958901716483896  [{hmjd: 58246.46433, mag: 19.302635, magerr: 0...  \n",
       "...                                                                ...  \n",
       "2099240375263563088  [{hmjd: 58285.38149, mag: 21.306799, magerr: 0...  \n",
       "2099240376120221204  [{hmjd: 58291.40441, mag: 21.441626, magerr: 0...  \n",
       "\n",
       "[921107 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ztf_single_pix = lsdb.open_catalog(\n",
    "    \"https://data.lsdb.io/hats/ztf_dr22\", search_filter=lsdb.PixelSearch((5, 7457))\n",
    ")\n",
    "ztf_single_pix = ztf_single_pix.nest_lists(\n",
    "    list_columns=[\"hmjd\", \"mag\", \"magerr\", \"clrcoeff\", \"catflags\"], name=\"lc\"\n",
    ").compute()\n",
    "ztf_single_pix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7fbd59",
   "metadata": {},
   "source": [
    "`info` is a nice way to check its characteristics, we see it's almost 8GBs in memory. While not specifically mentioned in the output, the vast majority of that will be the nested \"lc\" data. As an initial thought, we know from this that just holding the data will at worst cost 8GBs, meaning that immediately we've discounted having many ~8GB or smaller workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e39ff419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nested_pandas.nestedframe.core.NestedFrame'>\n",
      "Index: 921107 entries, 2098958901716483082 to 2099240376120221204\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count   Dtype                                                                                      \n",
      "---  ------    --------------   -----                                                                                      \n",
      " 0   objectid  921107 non-null  int64[pyarrow]                                                                             \n",
      " 1   filterid  921107 non-null  int8[pyarrow]                                                                              \n",
      " 2   objra     921107 non-null  float[pyarrow]                                                                             \n",
      " 3   objdec    921107 non-null  float[pyarrow]                                                                             \n",
      " 4   nepochs   921107 non-null  int64[pyarrow]                                                                             \n",
      " 5   lc        921107 non-null  nested<hmjd: [double], mag: [float], magerr: [float], clrcoeff: [float], catflags: [int32]>\n",
      "dtypes: float[pyarrow](2), int64[pyarrow](2), int8[pyarrow](1), nested<hmjd: [double], mag: [float], magerr: [float], clrcoeff: [float], catflags: [int32]>(1)\n",
      "memory usage: 7.7 GB\n"
     ]
    }
   ],
   "source": [
    "ztf_single_pix.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39298878",
   "metadata": {},
   "source": [
    "Now, let's create an analysis function that calculates the periods for each of our lightcurves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cef7da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_periods(pix_df):\n",
    "    \"\"\"Calculate the period of all objects in a pixel\"\"\"\n",
    "\n",
    "    # pix_df is a nested-pandas NestedFrame, so we use the NestedFrame API within this function\n",
    "    # First, cut our photometry on catflags\n",
    "    pix_df = pix_df.query(\"lc.catflags == 0\")\n",
    "\n",
    "    # Drop any empty light curves\n",
    "    pix_df = pix_df.dropna(subset=[\"lc\"])\n",
    "\n",
    "    # Now we can calculate the periods\n",
    "    extractor = licu.Extractor(\n",
    "        licu.Periodogram(\n",
    "            peaks=1,\n",
    "            max_freq_factor=1.0,\n",
    "            fast=True,\n",
    "        ),  # Would give two features: peak period and signa-to-noise ratio of the peak\n",
    "    )\n",
    "\n",
    "    # light-curve requires all arrays to be the same dtype.\n",
    "    # It also requires the time array to be ordered and to have no duplicates.\n",
    "    def _extract_features(mjd, mag, **kwargs):\n",
    "        # We offset date, so we still would have <1 second precision\n",
    "        if len(mjd) < 50:\n",
    "            return dict(zip(extractor.names, [np.nan] * len(extractor.names)))\n",
    "        t = np.asarray(mjd - 60000, dtype=np.float32)\n",
    "        # print(t)\n",
    "        _, sort_index = np.unique(t, return_index=True)\n",
    "        features = extractor(\n",
    "            t[sort_index],\n",
    "            mag[sort_index],\n",
    "            **kwargs,\n",
    "        )\n",
    "        # Return the features as a dictionary\n",
    "        return dict(zip(extractor.names, features))\n",
    "\n",
    "    features = pix_df.reduce(\n",
    "        _extract_features,\n",
    "        \"lc.hmjd\",\n",
    "        \"lc.mag\",\n",
    "    )\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1b098e",
   "metadata": {},
   "source": [
    "It's very useful to test our new analysis function on a single partition of the dataset, and we can easily use the one we just grabbed above. (For larger functions, it's also a great way to iteratively build those functions!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eaeebc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period_0</th>\n",
       "      <th>period_s_to_n_0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_healpix_29</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2098958901716483082</th>\n",
       "      <td>97.901375</td>\n",
       "      <td>9.427485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098958901716483896</th>\n",
       "      <td>56.258545</td>\n",
       "      <td>5.917771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099240375263563088</th>\n",
       "      <td>179.489136</td>\n",
       "      <td>4.851810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099240376120221204</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>909850 rows × 2 columns</p>"
      ],
      "text/plain": [
       "                       period_0  period_s_to_n_0\n",
       "_healpix_29                                     \n",
       "2098958901716483082   97.901375         9.427485\n",
       "2098958901716483896   56.258545         5.917771\n",
       "...                         ...              ...\n",
       "2099240375263563088  179.489136         4.851810\n",
       "2099240376120221204         NaN              NaN\n",
       "\n",
       "[909850 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the computed pixel to test the function\n",
    "single_res = calc_periods(ztf_single_pix)\n",
    "single_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2408ae38",
   "metadata": {},
   "source": [
    "We see above that our function works, and what it returns.\n",
    "\n",
    "Understanding what cluster parameters to use (number of workers, worker memory limits, etc.) can be a very tricky task. Especially when writing a custom function, as we have above, the needs of the cluster will directly depend on the memory demands of our function. Below, we use a memory profiler to estimate the amount of memory used for operating on a single partition. Above, we picked out one of the largest partitions in our sample, which positions this estimate as more of an upper bound to the needed worker memory.\n",
    "\n",
    "> **IMPORTANT: Memory Profiling Caveats**: It's very easy to use this incorrectly, especially within a notebook environment. Modules like this are almost always measuring the kernel memory, meaning it's not just a measure of the function run, but anything else in memory at the time. If you were to rerun this, you would see the number increasing every time, until garbage collection eventually stepped in. Running the single pixel calculation in the cell above would also affect the result. In principle, this number serves as a reasonable estimate if you restart the kernel and make sure to only run the needed cells ahead of running the memory profiler, and perhaps more ideally you would create a dedicated script executed separately to run the profiler. With these caveats in mind, this is still a useful exercise to get a rough sense of how much memory you will need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cb4f126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum memory used: 32424.65234375 MiB\n"
     ]
    }
   ],
   "source": [
    "# Assessing Memory Usage for a single pixel\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "\n",
    "def calc_periods_mem():\n",
    "    \"\"\"Calculate the period of all objects in a pixel, with memory profiling\"\"\"\n",
    "\n",
    "    return calc_periods(ztf_single_pix)\n",
    "\n",
    "\n",
    "mem = max(\n",
    "    memory_usage(\n",
    "        proc=calc_periods_mem,\n",
    "    )\n",
    ")\n",
    "print(\"Maximum memory used: {} MiB\".format(mem))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d49604b",
   "metadata": {},
   "source": [
    "We see that for our largest partition, our analysis required a bit more than 32 GBs of memory. As a rough hueristic, it's good to take this number and multiply it by 1.5-2x when defining memory limits. This overhead is for a couple reasons, dask will be storing intermediate results alongside doing these operations, and the largest partition we found may not be the largest partition in the full dataset. With a smaller number of workers, you might need closer to ~2x as those workers take on more burden in terms of storing intermediate results, whereas with a larger number of workers you might be able to operate comfortably at the ~1.5x regime. From a stability perspective, more worker memory is more reliable, but make sure to at least have a few workers.\n",
    "\n",
    "Below, we use this information to setup our cluster, allocating 4 workers with 48GBs each. And very importantly, we set this to be single-threaded via `threads_per_worker`, multi-threading can introduce more opportunities for workers to trip up and fail, especially when we're constructing our cluster parameters under the assumption that 1 worker is sized to handle about 1 (large) partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba5062cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>lsdb Catalog ztf_lc:</strong></div><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectid</th>\n",
       "      <th>filterid</th>\n",
       "      <th>objra</th>\n",
       "      <th>objdec</th>\n",
       "      <th>nepochs</th>\n",
       "      <th>lc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=39</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Order: 5, Pixel: 7261</th>\n",
       "      <td>int64[pyarrow]</td>\n",
       "      <td>int8[pyarrow]</td>\n",
       "      <td>float[pyarrow]</td>\n",
       "      <td>float[pyarrow]</td>\n",
       "      <td>int64[pyarrow]</td>\n",
       "      <td>nested&lt;hmjd: [double], mag: [float], magerr: [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Order: 6, Pixel: 29052</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Order: 6, Pixel: 29849</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Order: 6, Pixel: 29850</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><div>6 out of 6 columns in the catalog have been loaded <strong>lazily</strong>, meaning no data has been read, only the catalog schema</div>"
      ],
      "text/plain": [
       "Dask NestedFrame Structure:\n",
       "                           objectid       filterid           objra          objdec         nepochs                                                                                           lc\n",
       "npartitions=39                                                                                                                                                                                 \n",
       "2043789805896073216  int64[pyarrow]  int8[pyarrow]  float[pyarrow]  float[pyarrow]  int64[pyarrow]  nested<hmjd: [double], mag: [float], magerr: [float], clrcoeff: [float], catflags: [int32]>\n",
       "2044352755849494528             ...            ...             ...             ...             ...                                                                                          ...\n",
       "...                             ...            ...             ...             ...             ...                                                                                          ...\n",
       "2100507013703270400             ...            ...             ...             ...             ...                                                                                          ...\n",
       "2100577382447448064             ...            ...             ...             ...             ...                                                                                          ...\n",
       "Dask Name: lambda, 6 expressions\n",
       "Expr=MapPartitions(lambda)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a small cone around our largest partition\n",
    "ztf_cat = lsdb.open_catalog(\n",
    "    \"https://data.lsdb.io/hats/ztf_dr22\", search_filter=lsdb.ConeSearch(288.0, -13.0, radius_arcsec=11000.0)\n",
    ")\n",
    "ztf_cat = ztf_cat.nest_lists(list_columns=[\"hmjd\", \"mag\", \"magerr\", \"clrcoeff\", \"catflags\"], name=\"lc\")\n",
    "ztf_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e24e0d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>lsdb Catalog ztf_lc:</strong></div><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectid</th>\n",
       "      <th>filterid</th>\n",
       "      <th>objra</th>\n",
       "      <th>objdec</th>\n",
       "      <th>nepochs</th>\n",
       "      <th>lc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Order: 5, Pixel: 7457</th>\n",
       "      <td>int64[pyarrow]</td>\n",
       "      <td>int8[pyarrow]</td>\n",
       "      <td>float[pyarrow]</td>\n",
       "      <td>float[pyarrow]</td>\n",
       "      <td>int64[pyarrow]</td>\n",
       "      <td>nested&lt;hmjd: [double], mag: [float], magerr: [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><div>6 out of 6 columns in the catalog have been loaded <strong>lazily</strong>, meaning no data has been read, only the catalog schema</div>"
      ],
      "text/plain": [
       "Dask NestedFrame Structure:\n",
       "                           objectid       filterid           objra          objdec         nepochs                                                                                           lc\n",
       "npartitions=1                                                                                                                                                                                  \n",
       "2098958901331361792  int64[pyarrow]  int8[pyarrow]  float[pyarrow]  float[pyarrow]  int64[pyarrow]  nested<hmjd: [double], mag: [float], magerr: [float], clrcoeff: [float], catflags: [int32]>\n",
       "2099240376308072448             ...            ...             ...             ...             ...                                                                                          ...\n",
       "Dask Name: partitions, 7 expressions\n",
       "Expr=Partitions(frame=MapPartitions(lambda), partitions=[26])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that the largest pixel is actually here\n",
    "ztf_cat.pixel_search((5, 7457))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6c63be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 13:56:02,960 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 31.61 GiB -- Worker memory limit: 44.70 GiB\n",
      "2025-07-17 13:56:07,478 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 35.85 GiB -- Worker memory limit: 44.70 GiB\n",
      "2025-07-17 13:56:07,529 - distributed.worker.memory - WARNING - Worker is at 60% memory usage. Resuming worker. Process memory: 26.92 GiB -- Worker memory limit: 44.70 GiB\n"
     ]
    }
   ],
   "source": [
    "# Now we can do this in parallel across all pixels\n",
    "from dask.distributed import Client\n",
    "\n",
    "with Client(\n",
    "    dashboard_address=\"127.0.0.1:33709\", n_workers=4, memory_limit=\"48GB\", threads_per_worker=1\n",
    ") as client:\n",
    "    # We can use the map_partitions method to apply our function to each pixel\n",
    "    # Results from single pixel operations can be used for the meta, but use head(0) to not pass along the full data\n",
    "    full_res = ztf_cat.map_partitions(calc_periods, meta=single_res.head(0))\n",
    "    full_res = full_res.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff8e6b0",
   "metadata": {},
   "source": [
    "Despite our meticulous cluster crafting, we still get some worker memory warnings. These are acceptable, being that we only reach 80% memory at peak, but if you are seeing a lot of these warnings, that may be a sign to up the worker memory, especially for stability of larger jobs.\n",
    "\n",
    "> **Dask Tip**: You can also use the [Dashboard](https://docs.dask.org/en/latest/dashboard.html) to track the memory usage over the course of the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2703d96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period_0</th>\n",
       "      <th>period_s_to_n_0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_healpix_29</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2044053637065117179</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044053641978180364</th>\n",
       "      <td>276.323242</td>\n",
       "      <td>5.332016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100516122303696693</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100516153621180863</th>\n",
       "      <td>172.133255</td>\n",
       "      <td>3.879301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10372056 rows × 2 columns</p>"
      ],
      "text/plain": [
       "                       period_0  period_s_to_n_0\n",
       "_healpix_29                                     \n",
       "2044053637065117179         NaN              NaN\n",
       "2044053641978180364  276.323242         5.332016\n",
       "...                         ...              ...\n",
       "2100516122303696693         NaN              NaN\n",
       "2100516153621180863  172.133255         3.879301\n",
       "\n",
       "[10372056 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661d04f8",
   "metadata": {},
   "source": [
    "## About\n",
    "**Authors**: Doug Branton\n",
    "\n",
    "**Last updated on**: July 17, 2025\n",
    "\n",
    "If you use lsdb for published research, please cite following [instructions](https://docs.lsdb.io/en/stable/citation.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsdb_latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
