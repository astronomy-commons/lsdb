{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit test data\n",
    "\n",
    "This directory contains very small, toy, data sets that are used\n",
    "for unit tests.\n",
    "\n",
    "## Object catalog: small_sky\n",
    "\n",
    "This \"object catalog\" is 131 randomly generated radec values. \n",
    "\n",
    "- All radec positions are in the Healpix pixel order 0, pixel 11.\n",
    "- IDs are integers from 700-831."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T20:47:48.302610Z",
     "start_time": "2024-10-03T20:47:43.684052Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import astropy.units as u\n",
    "import hats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from astropy.coordinates import SkyCoord\n",
    "from dask.distributed import Client\n",
    "from hats.io.file_io import get_upath, remove_directory\n",
    "from hats.io.paths import DATASET_DIR\n",
    "from hats.pixel_math.spatial_index import healpix_to_spatial_index\n",
    "from hats_import import (\n",
    "    ImportArguments,\n",
    "    pipeline_with_client,\n",
    "    IndexArguments,\n",
    "    CollectionArguments,\n",
    "    MarginCacheArguments,\n",
    ")\n",
    "from lsdb.io import to_hats\n",
    "import lsdb\n",
    "\n",
    "tmp_path = tempfile.TemporaryDirectory()\n",
    "tmp_dir = tmp_path.name\n",
    "\n",
    "client = Client(n_workers=1, threads_per_worker=1, local_directory=tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small_sky_order1\n",
    "\n",
    "This catalog has the same data points as other small sky catalogs,\n",
    "but is coerced to spreading these data points over partitions at order 1, instead\n",
    "of order 0.\n",
    "\n",
    "This means there are 4 leaf partition files, instead of just 1, and so can\n",
    "be useful for confirming reads/writes over multiple leaf partition files.\n",
    "\n",
    "NB: Setting `constant_healpix_order` coerces the import pipeline to create\n",
    "leaf partitions at order 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T20:47:51.037190Z",
     "start_time": "2024-10-03T20:47:48.303875Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_directory(\"./small_sky_order1_collection\")\n",
    "with tempfile.TemporaryDirectory() as pipeline_tmp:\n",
    "    args = (\n",
    "        CollectionArguments(\n",
    "            output_artifact_name=\"small_sky_order1_collection\",\n",
    "            output_path=\".\",\n",
    "            tmp_dir=pipeline_tmp,\n",
    "            addl_hats_properties={\"obs_regime\": \"Optical\", \"default_index\": \"id\"},\n",
    "        )\n",
    "        .catalog(\n",
    "            input_file_list=[\"raw/small_sky/small_sky.csv\"],\n",
    "            file_reader=\"csv\",\n",
    "            output_artifact_name=\"small_sky_order1\",\n",
    "            constant_healpix_order=1,\n",
    "        )\n",
    "        .add_margin(\n",
    "            margin_threshold=3600, output_artifact_name=\"small_sky_order1_margin_1deg\", is_default=True\n",
    "        )\n",
    "        .add_margin(margin_threshold=7200, output_artifact_name=\"small_sky_order1_margin_2deg\")\n",
    "        .add_index(\n",
    "            indexing_column=\"id\",\n",
    "            output_artifact_name=\"small_sky_order1_id_index\",\n",
    "            include_healpix_29=False,\n",
    "            compute_partition_size=200_000,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small_sky_order1_no_pandas_meta\n",
    "\n",
    "Copies small_sky_order1 but removes the pandas metadata from the parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T20:48:09.007918Z",
     "start_time": "2024-10-18T20:48:08.932670Z"
    }
   },
   "outputs": [],
   "source": [
    "out_catalog_name = \"small_sky_order1_no_pandas_meta\"\n",
    "\n",
    "sso1 = hats.read_hats(\"small_sky_order1\")\n",
    "for pixel in sso1.get_healpix_pixels():\n",
    "    path = hats.io.paths.pixel_catalog_file(sso1.catalog_base_dir, pixel)\n",
    "    out_path = hats.io.paths.pixel_catalog_file(out_catalog_name, pixel)\n",
    "    table = pq.read_table(path, partitioning=None)\n",
    "    table = table.replace_schema_metadata()\n",
    "    output_file = Path(out_path)\n",
    "    output_file.parent.mkdir(exist_ok=True, parents=True)\n",
    "    pq.write_table(table, out_path)\n",
    "hats.io.write_parquet_metadata(out_catalog_name)\n",
    "sso1.catalog_info.copy_and_update(catalog_name=out_catalog_name).to_properties_file(out_catalog_name)\n",
    "sso1.partition_info.write_to_file(hats.io.paths.get_partition_info_pointer(out_catalog_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small_sky_order1_default_columns\n",
    "\n",
    "Copies small_sky_order1 but adds a list of default columns to the properties file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T18:41:22.261748Z",
     "start_time": "2025-01-23T18:41:22.230037Z"
    }
   },
   "outputs": [],
   "source": [
    "out_catalog_name = \"small_sky_order1_default_columns\"\n",
    "out_catalog_path = get_upath(out_catalog_name)\n",
    "\n",
    "sso1 = hats.read_hats(\"small_sky_order1_collection/small_sky_order1\")\n",
    "sso1_dataset_path = get_upath(\"small_sky_order1_collection/small_sky_order1\") / DATASET_DIR\n",
    "out_dataset_path = out_catalog_path / DATASET_DIR\n",
    "\n",
    "out_catalog_path.mkdir(exist_ok=True)\n",
    "if not out_dataset_path.exists():\n",
    "    os.symlink(f\"../{sso1_dataset_path}\", out_dataset_path)\n",
    "sso1.catalog_info.copy_and_update(\n",
    "    catalog_name=out_catalog_name, default_columns=[\"ra\", \"dec\", \"id\"]\n",
    ").to_properties_file(out_catalog_path)\n",
    "sso1.partition_info.write_to_file(hats.io.paths.get_partition_info_pointer(out_catalog_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small_sky\n",
    "\n",
    "This \"object catalog\" is 131 randomly generated radec values. \n",
    "\n",
    "- All radec positions are in the Healpix pixel order 0, pixel 11.\n",
    "- IDs are integers from 700-831.\n",
    "\n",
    "This catalog was generated with the following snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T20:47:51.121973Z",
     "start_time": "2024-10-03T20:47:51.038544Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_directory(\"./small_sky\")\n",
    "with tempfile.TemporaryDirectory() as pipeline_tmp:\n",
    "    args = ImportArguments(\n",
    "        input_file_list=[\"raw/small_sky/small_sky.csv\"],\n",
    "        output_path=\".\",\n",
    "        file_reader=\"csv\",\n",
    "        output_artifact_name=\"small_sky\",\n",
    "        tmp_dir=pipeline_tmp,\n",
    "        highest_healpix_order=5,\n",
    "    )\n",
    "    pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small_sky_npix_alt_suffix\n",
    "\n",
    "Copies small_sky but changes the parquet file suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import hats\n",
    "\n",
    "# hats/lsdb does not constrain the suffix,\n",
    "# but the suffix should make the file recognizable as parquet for compatibility with other libraries.\n",
    "npix_suffix = \".parq\"  # could also include the compression, e.g., \".snappy.parquet\"\n",
    "\n",
    "sso = hats.read_hats(\"small_sky\")\n",
    "paths = [hats.io.paths.pixel_catalog_file(sso.catalog_base_dir, pixel) for pixel in sso.get_healpix_pixels()]\n",
    "\n",
    "out_catalog_name = \"small_sky_npix_alt_suffix\"\n",
    "out_catalog_info = sso.catalog_info.copy_and_update(catalog_name=out_catalog_name, npix_suffix=npix_suffix)\n",
    "out_paths = [\n",
    "    hats.io.paths.pixel_catalog_file(out_catalog_name, pixel, npix_suffix=npix_suffix)\n",
    "    for pixel in sso.get_healpix_pixels()\n",
    "]\n",
    "\n",
    "for path, out_path in zip(paths, out_paths):\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy(path, out_path)\n",
    "hats.io.write_parquet_metadata(out_catalog_name)\n",
    "out_catalog_info.to_properties_file(out_catalog_name)\n",
    "sso.partition_info.write_to_file(hats.io.paths.get_partition_info_pointer(out_catalog_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small_sky_npix_as_dir\n",
    "\n",
    "Copies small_sky but makes Npix a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import hats\n",
    "\n",
    "npix_suffix = \"/\"\n",
    "\n",
    "sso = hats.read_hats(\"small_sky\")\n",
    "paths = [hats.io.paths.pixel_catalog_file(sso.catalog_base_dir, pixel) for pixel in sso.get_healpix_pixels()]\n",
    "\n",
    "out_catalog_name = \"small_sky_npix_as_dir\"\n",
    "out_catalog_info = sso.catalog_info.copy_and_update(catalog_name=out_catalog_name, npix_suffix=npix_suffix)\n",
    "out_dirs = [\n",
    "    hats.io.paths.pixel_catalog_file(out_catalog_name, pixel, npix_suffix=npix_suffix)\n",
    "    for pixel in sso.get_healpix_pixels()\n",
    "]\n",
    "\n",
    "for path, out_dir in zip(paths, out_dirs):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    # hats/lsdb will only care about `out_dir`. They will be agnostic to filenames, given `npix_suffix = \"/\"`.\n",
    "    shutil.copy(path, out_dir / \"part0.parquet\")\n",
    "hats.io.write_parquet_metadata(out_catalog_name)\n",
    "out_catalog_info.to_properties_file(out_catalog_name)\n",
    "sso.partition_info.write_to_file(hats.io.paths.get_partition_info_pointer(out_catalog_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object catalog: small_sky_source\n",
    "\n",
    "This \"source catalog\" is 131 detections at each of the 131 objects\n",
    "in the \"small_sky\" catalog. These have a random magnitude, MJD, and \n",
    "band (selected from ugrizy). The full script that generated the values\n",
    "can be found [here](https://github.com/delucchi-cmu/hipscripts/blob/main/twiddling/small_sky_source.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small_sky_order1_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T20:47:52.145198Z",
     "start_time": "2024-10-03T20:47:51.998275Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_directory(\"./small_sky_order1_source_collection\")\n",
    "with tempfile.TemporaryDirectory() as pipeline_tmp:\n",
    "    args = (\n",
    "        CollectionArguments(\n",
    "            output_artifact_name=\"small_sky_order1_source_collection\",\n",
    "            output_path=\".\",\n",
    "            tmp_dir=pipeline_tmp,\n",
    "            addl_hats_properties={\"obs_regime\": \"Optical\", \"default_index\": \"object_id\"},\n",
    "        )\n",
    "        .catalog(\n",
    "            input_file_list=[\"raw/small_sky_source/small_sky_source.csv\"],\n",
    "            file_reader=\"csv\",\n",
    "            ra_column=\"source_ra\",\n",
    "            dec_column=\"source_dec\",\n",
    "            catalog_type=\"source\",\n",
    "            output_artifact_name=\"small_sky_order1_source\",\n",
    "            constant_healpix_order=1,\n",
    "        )\n",
    "        .add_margin(\n",
    "            margin_threshold=7200, output_artifact_name=\"small_sky_order1_source_margin\", is_default=True\n",
    "        )\n",
    "        .add_index(\n",
    "            indexing_column=\"object_id\",\n",
    "            output_artifact_name=\"small_sky_order1_source_object_id_index\",\n",
    "            include_healpix_29=False,\n",
    "            compute_partition_size=200_000,\n",
    "        )\n",
    "        .add_index(\n",
    "            indexing_column=\"band\",\n",
    "            output_artifact_name=\"small_sky_order1_source_band_index\",\n",
    "            include_healpix_29=False,\n",
    "            compute_partition_size=200_000,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small_sky_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T20:47:52.362271Z",
     "start_time": "2024-10-03T20:47:52.146230Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_directory(\"./small_sky_source\")\n",
    "with tempfile.TemporaryDirectory() as pipeline_tmp:\n",
    "    args = ImportArguments(\n",
    "        input_file_list=[\"raw/small_sky_source/small_sky_source.csv\"],\n",
    "        output_path=\".\",\n",
    "        file_reader=\"csv\",\n",
    "        ra_column=\"source_ra\",\n",
    "        dec_column=\"source_dec\",\n",
    "        catalog_type=\"source\",\n",
    "        output_artifact_name=\"small_sky_source\",\n",
    "        highest_healpix_order=2,\n",
    "        add_healpix_29=False,\n",
    "        pixel_threshold=3000,\n",
    "        tmp_dir=pipeline_tmp,\n",
    "    )\n",
    "    pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small_sky_source_margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T20:47:53.573491Z",
     "start_time": "2024-10-03T20:47:52.362998Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_directory(\"./small_sky_source_margin\")\n",
    "with tempfile.TemporaryDirectory() as pipeline_tmp:\n",
    "    args = MarginCacheArguments(\n",
    "        input_catalog_path=\"small_sky_source\",\n",
    "        output_path=\".\",\n",
    "        output_artifact_name=\"small_sky_source_margin\",\n",
    "        margin_threshold=180,\n",
    "        margin_order=8,\n",
    "        tmp_dir=pipeline_tmp,\n",
    "    )\n",
    "    pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small_sky_order3_source_margin\n",
    "\n",
    "This one is similar to the previous margin catalogs but it is generated from a source catalog of order 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T20:48:00.070056Z",
     "start_time": "2024-10-03T20:47:56.532554Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_directory(\"./small_sky_order3_source\")\n",
    "with tempfile.TemporaryDirectory() as pipeline_tmp:\n",
    "    args = ImportArguments(\n",
    "        input_file_list=[\"raw/small_sky_source/small_sky_source.csv\"],\n",
    "        output_path=\".\",\n",
    "        file_reader=\"csv\",\n",
    "        ra_column=\"source_ra\",\n",
    "        dec_column=\"source_dec\",\n",
    "        catalog_type=\"source\",\n",
    "        output_artifact_name=\"small_sky_order3_source\",\n",
    "        constant_healpix_order=3,\n",
    "        tmp_dir=pipeline_tmp,\n",
    "    )\n",
    "    pipeline_with_client(args, client)\n",
    "\n",
    "remove_directory(\"./small_sky_order3_source_margin\")\n",
    "with tempfile.TemporaryDirectory() as pipeline_tmp:\n",
    "    args = MarginCacheArguments(\n",
    "        input_catalog_path=\"small_sky_order3_source\",\n",
    "        output_path=\".\",\n",
    "        output_artifact_name=\"small_sky_order3_source_margin\",\n",
    "        margin_threshold=300,\n",
    "        margin_order=7,\n",
    "        tmp_dir=pipeline_tmp,\n",
    "    )\n",
    "    pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested catalogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small_sky_order1_nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_directory(\"small_sky_order1_nested_sources\")\n",
    "small_sky_order1_catalog = lsdb.open_catalog(\"small_sky_order1\")\n",
    "small_sky_order1_source_with_margin = lsdb.open_catalog(\n",
    "    \"small_sky_order1_source\", margin_cache=\"small_sky_order1_source_margin\"\n",
    ")\n",
    "small_sky_order1_nested = small_sky_order1_catalog.join_nested(\n",
    "    small_sky_order1_source_with_margin, left_on=\"id\", right_on=\"object_id\", nested_column_name=\"sources\"\n",
    ")\n",
    "to_hats(\n",
    "    small_sky_order1_nested,\n",
    "    base_catalog_path=\"small_sky_order1_nested_sources\",\n",
    "    catalog_name=\"small_sky_order1_nested_sources\",\n",
    "    histogram_order=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small_sky_order1_nested_margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_directory(\"small_sky_order1_nested_sources_margin\")\n",
    "with tempfile.TemporaryDirectory() as pipeline_tmp:\n",
    "    args = MarginCacheArguments(\n",
    "        input_catalog_path=\"small_sky_order1_nested_sources\",\n",
    "        output_path=\".\",\n",
    "        output_artifact_name=\"small_sky_order1_nested_sources_margin\",\n",
    "        margin_threshold=7200,\n",
    "        margin_order=4,\n",
    "        tmp_dir=pipeline_tmp,\n",
    "    )\n",
    "    pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connections between tables\n",
    "\n",
    "### small_sky_to_o1source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T20:48:00.180200Z",
     "start_time": "2024-10-03T20:48:00.072426Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_directory(\"small_sky_to_o1source\")\n",
    "\n",
    "small_sky_catalog = lsdb.open_catalog(\"small_sky\")\n",
    "small_sky_order1_source = lsdb.open_catalog(\"small_sky_order1_source_collection\")\n",
    "small_sky_order1source = small_sky_catalog.crossmatch(small_sky_order1_source, radius_arcsec=3600)\n",
    "\n",
    "association_kwargs = {\n",
    "    \"primary_catalog_dir\": \"small_sky\",\n",
    "    \"primary_column_association\": \"id_small_sky\",\n",
    "    \"primary_id_column\": \"id\",\n",
    "    \"join_catalog_dir\": \"small_sky_order1_source_collection\",\n",
    "    \"join_column_association\": \"source_id_small_sky_order1_source\",\n",
    "    \"join_id_column\": \"source_id\",\n",
    "}\n",
    "\n",
    "lsdb.io.to_association(\n",
    "    small_sky_order1source[[\"id_small_sky\", \"source_id_small_sky_order1_source\", \"_dist_arcsec\"]],\n",
    "    base_catalog_path=\"small_sky_to_o1source\",\n",
    "    catalog_name=\"small_sky_to_o1source\",\n",
    "    separation_column=\"_dist_arcsec\",\n",
    "    **association_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbed object catalog\n",
    "\n",
    "In order to test validity of cross match, we create a new version of the \"small sky\" catalog where each radec is slightly perturbed.\n",
    "\n",
    "### small_sky_xmatch\n",
    "\n",
    "The initial perturbation is stored as a CSV, and we can re-import from this raw data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T20:48:00.363489Z",
     "start_time": "2024-10-03T20:48:00.259302Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_directory(\"./small_sky_xmatch\")\n",
    "with tempfile.TemporaryDirectory() as pipeline_tmp:\n",
    "    args = ImportArguments(\n",
    "        input_file_list=[\"raw/xmatch/small_sky_xmatch.csv\"],\n",
    "        output_path=\".\",\n",
    "        file_reader=\"csv\",\n",
    "        output_artifact_name=\"small_sky_xmatch\",\n",
    "        pixel_threshold=100,\n",
    "        tmp_dir=pipeline_tmp,\n",
    "        highest_healpix_order=4,\n",
    "    )\n",
    "    pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small_sky_xmatch_margin\n",
    "\n",
    "Create a margin catalog from the perturbed data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T20:48:00.694676Z",
     "start_time": "2024-10-03T20:48:00.508540Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_directory(\"./small_sky_xmatch_margin\")\n",
    "with tempfile.TemporaryDirectory() as pipeline_tmp:\n",
    "    args = MarginCacheArguments(\n",
    "        input_catalog_path=\"small_sky_xmatch\",\n",
    "        output_path=\".\",\n",
    "        output_artifact_name=\"small_sky_xmatch_margin\",\n",
    "        margin_threshold=7200,\n",
    "        margin_order=4,\n",
    "        tmp_dir=pipeline_tmp,\n",
    "    )\n",
    "    pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small_sky_left_xmatch\n",
    "\n",
    "This adds a new point that's outside of the (0,11) pixel of the small sky catalog. Otherwise, the points are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T20:48:00.878810Z",
     "start_time": "2024-10-03T20:48:00.696977Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_directory(\"./small_sky_left_xmatch\")\n",
    "with tempfile.TemporaryDirectory() as pipeline_tmp:\n",
    "    args = ImportArguments(\n",
    "        input_file_list=[\"raw/xmatch/small_sky_left_xmatch.csv\"],\n",
    "        output_path=\".\",\n",
    "        file_reader=\"csv\",\n",
    "        output_artifact_name=\"small_sky_left_xmatch\",\n",
    "        pixel_threshold=100,\n",
    "        tmp_dir=pipeline_tmp,\n",
    "        highest_healpix_order=2,\n",
    "    )\n",
    "    pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Expected Results Files\n",
    "\n",
    "### Small Sky Source Cone Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T20:48:00.888314Z",
     "start_time": "2024-10-03T20:48:00.882342Z"
    }
   },
   "outputs": [],
   "source": [
    "ss_source = hats.read_hats(\"small_sky_order1_source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T20:48:00.891302Z",
     "start_time": "2024-10-03T20:48:00.889229Z"
    }
   },
   "outputs": [],
   "source": [
    "ra = -35\n",
    "dec = -55\n",
    "radius_degrees = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T20:48:00.915271Z",
     "start_time": "2024-10-03T20:48:00.892006Z"
    }
   },
   "outputs": [],
   "source": [
    "paths = [hats.io.pixel_catalog_file(ss_source.catalog_base_dir, p) for p in ss_source.get_healpix_pixels()]\n",
    "ss_source_df = pd.concat([pd.read_parquet(p) for p in paths])\n",
    "coords = SkyCoord(\n",
    "    ss_source_df[\"source_ra\"].to_numpy() * u.deg, ss_source_df[\"source_dec\"].to_numpy() * u.deg, frame=\"icrs\"\n",
    ")\n",
    "center_coord = SkyCoord(ra * u.deg, dec * u.deg, frame=\"icrs\")\n",
    "cone_search_output = ss_source_df.iloc[coords.separation(center_coord).deg < radius_degrees]\n",
    "cone_search_output.to_csv(\"raw/cone_search_expected/catalog.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Sky Source Margin Cone Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T20:48:00.921743Z",
     "start_time": "2024-10-03T20:48:00.916331Z"
    }
   },
   "outputs": [],
   "source": [
    "ss_source_margin = hats.read_hats(\"small_sky_order1_source_margin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T20:48:00.938571Z",
     "start_time": "2024-10-03T20:48:00.922642Z"
    }
   },
   "outputs": [],
   "source": [
    "paths = [\n",
    "    hats.io.pixel_catalog_file(ss_source_margin.catalog_base_dir, p)\n",
    "    for p in ss_source_margin.get_healpix_pixels()\n",
    "]\n",
    "ss_source_margin_df = pd.concat([pd.read_parquet(p) for p in paths])\n",
    "coords = SkyCoord(\n",
    "    ss_source_margin_df[\"source_ra\"].to_numpy() * u.deg,\n",
    "    ss_source_margin_df[\"source_dec\"].to_numpy() * u.deg,\n",
    "    frame=\"icrs\",\n",
    ")\n",
    "center_coord = SkyCoord(ra * u.deg, dec * u.deg, frame=\"icrs\")\n",
    "cone_search_output = ss_source_margin_df.iloc[coords.separation(center_coord).deg < radius_degrees]\n",
    "cone_search_output.to_csv(\"raw/cone_search_expected/margin.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Square map\n",
    "\n",
    "Create a trivial map-type catalog. This just contains a `star_count` per order 0\n",
    "healpix tile. The value is the square of the healpix index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pixels = np.arange(0, 12)\n",
    "\n",
    "healpix_29 = healpix_to_spatial_index(0, target_pixels)\n",
    "\n",
    "square_vals = target_pixels * target_pixels\n",
    "value_frame = pd.DataFrame({\"_healpix_29\": healpix_29, \"star_count\": square_vals})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_directory(\"./square_map\")\n",
    "with tempfile.TemporaryDirectory() as pipeline_tmp:\n",
    "    csv_file = Path(pipeline_tmp) / \"square_map.csv\"\n",
    "    value_frame.to_csv(csv_file, index=False)\n",
    "    args = ImportArguments(\n",
    "        constant_healpix_order=0,  ## forces the moc to order 0.\n",
    "        catalog_type=\"map\",\n",
    "        use_healpix_29=True,\n",
    "        ra_column=None,\n",
    "        dec_column=None,\n",
    "        file_reader=\"csv\",\n",
    "        input_file_list=[csv_file],\n",
    "        output_artifact_name=\"square_map\",\n",
    "        output_path=\".\",\n",
    "        tmp_dir=pipeline_tmp,\n",
    "    )\n",
    "\n",
    "    pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T20:48:01.524993Z",
     "start_time": "2024-10-03T20:48:00.940037Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp_path.cleanup()\n",
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
